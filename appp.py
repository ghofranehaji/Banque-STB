import streamlit as st
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from scipy.spatial.distance import cdist
import joblib

def main():
    st.title("üîç Estimation du segment carte de cr√©dit")
    st.markdown("Cette application estime le segment d'un client selon un clustering hi√©rarchique d√©j√† r√©alis√© sur les donn√©es historiques.")

    # === 1. Chargement des donn√©es ===
    try:
        df = pd.read_csv('clustering_carte_credit.csv', sep=";", encoding='latin-1')
    except FileNotFoundError:
        st.error("‚ùå Fichier 'clustering_carte_credit.csv' non trouv√©. V√©rifiez le chemin du fichier.")
        return

    # === 2. Colonnes utilis√©es pour la pr√©diction ===
    features = ['Age', 'salaire', 'Frequence_Paiements', 'Total_des_cheques']
    if not all(f in df.columns for f in features + ['segment_carte_credit']):
        st.error("‚ùå Certaines colonnes n√©cessaires sont manquantes dans le fichier.")
        return

    X = df[features]

    # === 3. Standardisation ===
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # === 4. Cr√©ation du DataFrame standardis√© avec segments ===
    df_scaled = pd.DataFrame(X_scaled, columns=features)
    df_scaled['segment'] = df['segment_carte_credit']

    # === 5. Calcul des centro√Ødes de chaque segment (approche manuelle) ===
    centroids = df_scaled.groupby('segment').mean().values
    segments_labels = df_scaled.groupby('segment').mean().index.tolist()

    # === 6. D√©tection des valeurs aberrantes pour chaque variable ===
    limits = {}
    for feature in features:
        q1 = df[feature].quantile(0.25)
        q3 = df[feature].quantile(0.75)
        iqr = q3 - q1
        min_valid = q1 - 1.5 * iqr
        max_valid = q3 + 1.5 * iqr
        limits[feature] = (min_valid, max_valid)

    # === 7. Interface utilisateur ===
    st.subheader("üßæ Entrer les informations du client")
    age = st.number_input("√Çge", min_value=18, max_value=100)
    salaire = st.number_input("Salaire", min_value=450, max_value=10000)
    frequence = st.number_input("Fr√©quence des paiements", min_value=1, max_value=1000)
    total_cheques = st.number_input("Total des ch√®ques", min_value=1, max_value=100000)

    if st.button("üìä Pr√©dire le segment"):
        new_data = {'Age': age, 'salaire': salaire, 'Frequence_Paiements': frequence, 'Total_des_cheques': total_cheques}
        anomalies = [f"{k} ({v})" for k, v in new_data.items() if not (limits[k][0] <= v <= limits[k][1])]

        if anomalies:
            st.warning(f"‚ùå Valeurs anormales d√©tect√©es pour : {', '.join(anomalies)}. Veuillez corriger les saisies.")
        else:
            new_client = np.array([[age, salaire, frequence, total_cheques]])
            new_client_scaled = scaler.transform(new_client)

            # Distance du client √† chaque centro√Øde
            distances = cdist(new_client_scaled, centroids)
            closest = distances.argmin()
            predicted_segment = segments_labels[closest]
            st.success(f"‚úÖ Segment estim√© du client : **{predicted_segment}**")

    # === 8. Option de sauvegarde ===
    if st.checkbox("üíæ Sauvegarder le scaler et les centro√Ødes"):
        joblib.dump(scaler, 'scaler.pkl')
        np.save('centroids.npy', centroids)
        np.save('segments_labels.npy', np.array(segments_labels))
        st.info("‚úÖ Sauvegarde effectu√©e avec succ√®s.")

# ‚úÖ Point d'entr√©e
if __name__ == "__main__":
    main()
